{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32c55fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration loaded\n",
      "ðŸ“Š Analyzing 6 companies: ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA']\n",
      "ðŸ“ˆ Technical analysis directory: d:\\10 acadamy\\Financial_News_Stock_Analysis\\data\\technical\n",
      "ðŸ˜Š Sentiment analysis directory: d:\\10 acadamy\\Financial_News_Stock_Analysis\\data\\sentiment\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory (project root) to the system path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Now we can import from src\n",
    "from src.data_loader import load_news_data, validate_news_data\n",
    "from src.config import TICKERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f14a04bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Feature Engineering Pipeline...\n",
      "Tickers: ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA']\n",
      "Technical data: d:/10 acadamy/Financial_News_Stock_Analysis/data/technical\n",
      "Sentiment data: d:/10 acadamy/Financial_News_Stock_Analysis/data/sentiment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration from your setup\n",
    "TICKERS = ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA']\n",
    "TECHNICAL_DIR = 'd:/10 acadamy/Financial_News_Stock_Analysis/data/technical'\n",
    "SENTIMENT_DIR = 'd:/10 acadamy/Financial_News_Stock_Analysis/data/sentiment'\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "\n",
    "print(\"ðŸš€ Starting Feature Engineering Pipeline...\")\n",
    "print(f\"Tickers: {TICKERS}\")\n",
    "print(f\"Technical data: {TECHNICAL_DIR}\")\n",
    "print(f\"Sentiment data: {SENTIMENT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ada0851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Creating sample data for feature engineering...\n",
      "âœ… Created sample data: 2196 rows, 6 tickers\n",
      "\n",
      "ðŸ“Š Sample data created successfully!\n",
      "Shape: (2196, 11)\n",
      "Columns: ['date', 'ticker', 'open', 'high', 'low', 'close', 'volume', 'daily_compound_mean', 'positive', 'negative', 'neutral']\n",
      "Date range: 2023-01-01 00:00:00 to 2024-01-01 00:00:00\n",
      "Tickers: ['AAPL' 'AMZN' 'GOOG' 'META' 'MSFT' 'NVDA']\n"
     ]
    }
   ],
   "source": [
    "def create_sample_data():\n",
    "    \"\"\"Create sample technical and sentiment data for testing\"\"\"\n",
    "    print(\"ðŸ“ Creating sample data for feature engineering...\")\n",
    "    \n",
    "    # Create date range\n",
    "    dates = pd.date_range(start='2023-01-01', end='2024-01-01', freq='D')\n",
    "    \n",
    "    sample_data = []\n",
    "    \n",
    "    for ticker in TICKERS:\n",
    "        # Base price for each stock\n",
    "        base_price = {\n",
    "            'AAPL': 150, 'AMZN': 130, 'GOOG': 100, \n",
    "            'META': 250, 'MSFT': 300, 'NVDA': 400\n",
    "        }.get(ticker, 100)\n",
    "        \n",
    "        for i, date in enumerate(dates):\n",
    "            # Generate realistic price data with some trend and noise\n",
    "            trend = i * 0.1\n",
    "            noise = np.random.normal(0, 2)\n",
    "            price = base_price + trend + noise\n",
    "            \n",
    "            # Ensure prices are positive\n",
    "            price = max(10, price)\n",
    "            \n",
    "            # Generate OHLC data\n",
    "            open_price = price * (1 + np.random.normal(0, 0.01))\n",
    "            high = max(open_price, price) * (1 + abs(np.random.normal(0, 0.02)))\n",
    "            low = min(open_price, price) * (1 - abs(np.random.normal(0, 0.02)))\n",
    "            close = price\n",
    "            volume = np.random.randint(1000000, 10000000)\n",
    "            \n",
    "            # Generate sentiment data with some correlation to returns\n",
    "            base_sentiment = np.random.normal(0, 0.1)\n",
    "            # Add some correlation with price movements\n",
    "            if i > 0:\n",
    "                prev_close = sample_data[-1]['close'] if sample_data else base_price\n",
    "                price_change = (close - prev_close) / prev_close\n",
    "                sentiment = base_sentiment + price_change * 0.3\n",
    "            else:\n",
    "                sentiment = base_sentiment\n",
    "            \n",
    "            sample_data.append({\n",
    "                'date': date,\n",
    "                'ticker': ticker,\n",
    "                'open': open_price,\n",
    "                'high': high,\n",
    "                'low': low,\n",
    "                'close': close,\n",
    "                'volume': volume,\n",
    "                'daily_compound_mean': sentiment,\n",
    "                'positive': max(0, sentiment),\n",
    "                'negative': min(0, -sentiment),\n",
    "                'neutral': 1 - abs(sentiment)\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    print(f\"âœ… Created sample data: {len(df)} rows, {df['ticker'].nunique()} tickers\")\n",
    "    return df\n",
    "\n",
    "# Create sample data\n",
    "merged_data = create_sample_data()\n",
    "\n",
    "print(f\"\\nðŸ“Š Sample data created successfully!\")\n",
    "print(f\"Shape: {merged_data.shape}\")\n",
    "print(f\"Columns: {merged_data.columns.tolist()}\")\n",
    "print(f\"Date range: {merged_data['date'].min()} to {merged_data['date'].max()}\")\n",
    "print(f\"Tickers: {merged_data['ticker'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "768030c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Feature Engineering Pipeline...\n",
      "Tickers: ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA']\n",
      "ðŸ“Š Checking for existing data...\n",
      "âœ… Loading existing merged data from: ../data/processed\\sentiment_returns_merged.csv\n",
      "Loaded: 4000 rows, 8 tickers\n",
      "\n",
      "ðŸ“Š Data loaded successfully!\n",
      "Shape: (4000, 6)\n",
      "Columns: ['date', 'daily_compound_mean', 'ticker', 'close', 'return', 'next_return']\n",
      "Date range: 2023-11-27 to 2025-11-21\n",
      "Tickers: ['AAPL' 'GOOGL' 'MSFT' 'TSLA' 'AMZN' 'META' 'NFLX' 'NVDA']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "TICKERS = ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA']\n",
    "TECHNICAL_DIR = 'd:/10 acadamy/Financial_News_Stock_Analysis/data/technical'\n",
    "SENTIMENT_DIR = 'd:/10 acadamy/Financial_News_Stock_Analysis/data/sentiment'\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "\n",
    "print(\"ðŸš€ Starting Feature Engineering Pipeline...\")\n",
    "print(f\"Tickers: {TICKERS}\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Remove the undefined merged_dir line and replace with proper data loading\n",
    "def load_or_create_data():\n",
    "    \"\"\"Load existing data or create sample data for feature engineering\"\"\"\n",
    "    print(\"ðŸ“Š Checking for existing data...\")\n",
    "    \n",
    "    # Check if we have saved merged data from previous steps\n",
    "    merged_data_path = os.path.join(PROCESSED_DIR, \"sentiment_returns_merged.csv\")\n",
    "    \n",
    "    if os.path.exists(merged_data_path):\n",
    "        print(f\"âœ… Loading existing merged data from: {merged_data_path}\")\n",
    "        merged_data = pd.read_csv(merged_data_path)\n",
    "        print(f\"Loaded: {len(merged_data)} rows, {merged_data['ticker'].nunique()} tickers\")\n",
    "        return merged_data\n",
    "    else:\n",
    "        print(\"âŒ No existing merged data found. Creating sample data...\")\n",
    "        return create_sample_data()\n",
    "\n",
    "def create_sample_data():\n",
    "    \"\"\"Create sample technical and sentiment data for testing\"\"\"\n",
    "    print(\"ðŸ“ Creating sample data for feature engineering...\")\n",
    "    \n",
    "    # Create date range\n",
    "    dates = pd.date_range(start='2023-01-01', end='2024-01-01', freq='D')\n",
    "    \n",
    "    sample_data = []\n",
    "    \n",
    "    for ticker in TICKERS:\n",
    "        # Base price for each stock\n",
    "        base_price = {\n",
    "            'AAPL': 150, 'AMZN': 130, 'GOOG': 100, \n",
    "            'META': 250, 'MSFT': 300, 'NVDA': 400\n",
    "        }.get(ticker, 100)\n",
    "        \n",
    "        for i, date in enumerate(dates):\n",
    "            # Generate realistic price data with some trend and noise\n",
    "            trend = i * 0.1\n",
    "            noise = np.random.normal(0, 2)\n",
    "            price = base_price + trend + noise\n",
    "            \n",
    "            # Ensure prices are positive\n",
    "            price = max(10, price)\n",
    "            \n",
    "            # Generate OHLC data\n",
    "            open_price = price * (1 + np.random.normal(0, 0.01))\n",
    "            high = max(open_price, price) * (1 + abs(np.random.normal(0, 0.02)))\n",
    "            low = min(open_price, price) * (1 - abs(np.random.normal(0, 0.02)))\n",
    "            close = price\n",
    "            volume = np.random.randint(1000000, 10000000)\n",
    "            \n",
    "            # Generate sentiment data with some correlation to returns\n",
    "            base_sentiment = np.random.normal(0, 0.1)\n",
    "            # Add some correlation with price movements\n",
    "            if i > 0:\n",
    "                prev_close = sample_data[-1]['close'] if sample_data else base_price\n",
    "                price_change = (close - prev_close) / prev_close\n",
    "                sentiment = base_sentiment + price_change * 0.3\n",
    "            else:\n",
    "                sentiment = base_sentiment\n",
    "            \n",
    "            sample_data.append({\n",
    "                'date': date,\n",
    "                'ticker': ticker,\n",
    "                'open': open_price,\n",
    "                'high': high,\n",
    "                'low': low,\n",
    "                'close': close,\n",
    "                'volume': volume,\n",
    "                'daily_compound_mean': sentiment,\n",
    "                'positive': max(0, sentiment),\n",
    "                'negative': min(0, -sentiment),\n",
    "                'neutral': 1 - abs(sentiment)\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    print(f\"âœ… Created sample data: {len(df)} rows, {df['ticker'].nunique()} tickers\")\n",
    "    return df\n",
    "\n",
    "# Load or create data\n",
    "merged_data = load_or_create_data()\n",
    "\n",
    "print(f\"\\nðŸ“Š Data loaded successfully!\")\n",
    "print(f\"Shape: {merged_data.shape}\")\n",
    "print(f\"Columns: {merged_data.columns.tolist()}\")\n",
    "print(f\"Date range: {merged_data['date'].min()} to {merged_data['date'].max()}\")\n",
    "print(f\"Tickers: {merged_data['ticker'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Applying technical indicators...\n",
      "ðŸ”§ Computing technical indicators...\n",
      "  Processing AAPL...\n",
      "  Processing AMZN...\n",
      "  Processing GOOGL...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing META...\n",
      "  Processing MSFT...\n",
      "  Processing NFLX...\n",
      "  Processing NVDA...\n",
      "  Processing TSLA...\n",
      "âœ… Technical indicators computed successfully!\n",
      "\n",
      "ðŸŽ¯ TECHNICAL INDICATORS APPLIED SUCCESSFULLY!\n",
      "Final data shape: (4000, 25)\n",
      "Total columns: 25\n",
      "Technical columns created: 21\n",
      "Sample technical columns: ['return', 'next_return', 'log_return', 'sma_5', 'sma_10', 'sma_20', 'sma_50', 'ema_12', 'ema_26', 'price_vs_sma_20']...\n",
      "\n",
      "ðŸ“Š BASIC STATISTICS:\n",
      "Mean return: 0.001546\n",
      "Return std: 0.024586\n",
      "RSI range: 6.92 - 100.00\n",
      "Data points per ticker: {'AAPL': 500, 'AMZN': 500, 'GOOGL': 500, 'META': 500, 'MSFT': 500, 'NFLX': 500, 'NVDA': 500, 'TSLA': 500}\n"
     ]
    }
   ],
   "source": [
    "def compute_technical_indicators(df):\n",
    "    \"\"\"Compute comprehensive technical indicators - FIXED VERSION\"\"\"\n",
    "    print(\"ðŸ”§ Computing technical indicators...\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['ticker', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for ticker in df['ticker'].unique():\n",
    "        print(f\"  Processing {ticker}...\")\n",
    "        ticker_data = df[df['ticker'] == ticker].copy()\n",
    "        \n",
    "        # Price-based features\n",
    "        if 'close' in ticker_data.columns:\n",
    "            # Returns\n",
    "            ticker_data['return'] = ticker_data['close'].pct_change()\n",
    "            ticker_data['log_return'] = np.log(ticker_data['close'] / ticker_data['close'].shift(1))\n",
    "            \n",
    "            # Moving averages - FIXED: Use direct computation without reset_index\n",
    "            for window in [5, 10, 20, 50]:\n",
    "                ticker_data[f'sma_{window}'] = ticker_data['close'].rolling(window=window).mean()\n",
    "            \n",
    "            # Exponential moving averages\n",
    "            ticker_data['ema_12'] = ticker_data['close'].ewm(span=12).mean()\n",
    "            ticker_data['ema_26'] = ticker_data['close'].ewm(span=26).mean()\n",
    "            \n",
    "            # Price position relative to moving averages\n",
    "            ticker_data['price_vs_sma_20'] = (ticker_data['close'] - ticker_data['sma_20']) / ticker_data['sma_20']\n",
    "            ticker_data['price_vs_sma_50'] = (ticker_data['close'] - ticker_data['sma_50']) / ticker_data['sma_50']\n",
    "            \n",
    "            # Volatility\n",
    "            ticker_data['volatility_5d'] = ticker_data['return'].rolling(5).std()\n",
    "            ticker_data['volatility_20d'] = ticker_data['return'].rolling(20).std()\n",
    "            \n",
    "            # High-Low features\n",
    "            if all(col in ticker_data.columns for col in ['high', 'low']):\n",
    "                ticker_data['high_low_range'] = (ticker_data['high'] - ticker_data['low']) / ticker_data['close']\n",
    "                ticker_data['high_low_ratio'] = ticker_data['high'] / ticker_data['low']\n",
    "        \n",
    "        # Volume features\n",
    "        if 'volume' in ticker_data.columns:\n",
    "            ticker_data['volume_sma_5'] = ticker_data['volume'].rolling(5).mean()\n",
    "            ticker_data['volume_sma_20'] = ticker_data['volume'].rolling(20).mean()\n",
    "            ticker_data['volume_ratio_5'] = ticker_data['volume'] / ticker_data['volume_sma_5']\n",
    "            ticker_data['volume_ratio_20'] = ticker_data['volume'] / ticker_data['volume_sma_20']\n",
    "            \n",
    "            # Volume-price relationship\n",
    "            if 'return' in ticker_data.columns:\n",
    "                ticker_data['volume_price_trend'] = ticker_data['volume'] * ticker_data['return'].abs()\n",
    "        \n",
    "        # RSI calculation\n",
    "        if 'close' in ticker_data.columns:\n",
    "            def compute_rsi(series, period=14):\n",
    "                delta = series.diff()\n",
    "                gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "                loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "                rs = gain / loss\n",
    "                rsi = 100 - (100 / (1 + rs))\n",
    "                return rsi\n",
    "            \n",
    "            ticker_data['rsi_14'] = compute_rsi(ticker_data['close'], 14)\n",
    "        \n",
    "        # MACD calculation\n",
    "        if 'close' in ticker_data.columns:\n",
    "            def compute_macd(series):\n",
    "                ema_fast = series.ewm(span=12).mean()\n",
    "                ema_slow = series.ewm(span=26).mean()\n",
    "                macd = ema_fast - ema_slow\n",
    "                macd_signal = macd.ewm(span=9).mean()\n",
    "                macd_histogram = macd - macd_signal\n",
    "                return macd, macd_signal, macd_histogram\n",
    "            \n",
    "            macd, signal, hist = compute_macd(ticker_data['close'])\n",
    "            ticker_data['macd'] = macd\n",
    "            ticker_data['macd_signal'] = signal\n",
    "            ticker_data['macd_hist'] = hist\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        if 'close' in ticker_data.columns:\n",
    "            def compute_bollinger_bands(series, period=20, std=2):\n",
    "                sma = series.rolling(window=period).mean()\n",
    "                rolling_std = series.rolling(window=period).std()\n",
    "                upper_band = sma + (rolling_std * std)\n",
    "                lower_band = sma - (rolling_std * std)\n",
    "                bandwidth = (upper_band - lower_band) / sma\n",
    "                position = (series - lower_band) / (upper_band - lower_band)\n",
    "                return upper_band, lower_band, bandwidth, position\n",
    "            \n",
    "            upper, lower, width, pos = compute_bollinger_bands(ticker_data['close'])\n",
    "            ticker_data['bb_upper'] = upper\n",
    "            ticker_data['bb_lower'] = lower\n",
    "            ticker_data['bb_width'] = width\n",
    "            ticker_data['bb_position'] = pos\n",
    "        \n",
    "        results.append(ticker_data)\n",
    "    \n",
    "    # Combine all tickers\n",
    "    df_final = pd.concat(results, ignore_index=True)\n",
    "    print(\"âœ… Technical indicators computed successfully!\")\n",
    "    return df_final\n",
    "\n",
    "# Apply technical indicators\n",
    "print(\"\\nðŸš€ Applying technical indicators...\")\n",
    "merged_data = compute_technical_indicators(merged_data)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nðŸŽ¯ TECHNICAL INDICATORS APPLIED SUCCESSFULLY!\")\n",
    "print(f\"Final data shape: {merged_data.shape}\")\n",
    "print(f\"Total columns: {len(merged_data.columns)}\")\n",
    "\n",
    "# Show the technical columns that were added\n",
    "tech_columns = [col for col in merged_data.columns if any(x in col for x in \n",
    "                ['sma', 'ema', 'rsi', 'macd', 'bb', 'volatility', 'return'])]\n",
    "print(f\"Technical columns created: {len(tech_columns)}\")\n",
    "print(f\"Sample technical columns: {tech_columns[:10]}...\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"\\nðŸ“Š BASIC STATISTICS:\")\n",
    "print(f\"Mean return: {merged_data['return'].mean():.6f}\")\n",
    "print(f\"Return std: {merged_data['return'].std():.6f}\")\n",
    "if 'rsi_14' in merged_data.columns:\n",
    "    print(f\"RSI range: {merged_data['rsi_14'].min():.2f} - {merged_data['rsi_14'].max():.2f}\")\n",
    "print(f\"Data points per ticker: {merged_data.groupby('ticker').size().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fff4a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”§ Running complete feature engineering pipeline...\n",
      "\n",
      "ðŸ˜Š Engineering sentiment features...\n",
      "âœ… Sentiment features engineered\n",
      "ðŸŽ¯ Creating target variables...\n",
      "âœ… Target variables created\n",
      "ðŸ§¹ Finalizing features...\n",
      "   Rows before cleaning: 4,000\n",
      "   Rows after cleaning: 3,568\n",
      "   Total columns: 46\n",
      "\n",
      "ðŸ“Š FEATURE SUMMARY:\n",
      "   Price Features: 23 features\n",
      "   Volume Features: 0 features\n",
      "   Technical Indicators: 8 features\n",
      "   Sentiment Features: 16 features\n",
      "   Target Variables: 6 features\n",
      "\n",
      "ðŸŽ‰ FEATURE ENGINEERING COMPLETED!\n",
      "Final dataset shape: (3568, 46)\n",
      "Total features: 46\n",
      "ðŸ’¾ Engineered features saved to: ../data/processed\\engineered_features.csv\n",
      "\n",
      "ðŸ“‹ Sample of engineered features:\n",
      "   ticker        date       close    return      sma_20     rsi_14  \\\n",
      "49   AAPL  2024-02-07  187.637970  0.000581  187.114400  51.600991   \n",
      "50   AAPL  2024-02-08  186.558151 -0.005755  187.219904  42.806363   \n",
      "51   AAPL  2024-02-09  187.321930  0.004094  187.393317  38.552551   \n",
      "52   AAPL  2024-02-12  185.635666 -0.009002  187.466071  31.773530   \n",
      "53   AAPL  2024-02-13  183.542740 -0.011274  187.547607  29.777432   \n",
      "54   AAPL  2024-02-14  182.659927 -0.004810  187.632058  29.062331   \n",
      "55   AAPL  2024-02-15  182.372299 -0.001575  187.407410  30.998725   \n",
      "56   AAPL  2024-02-16  180.834839 -0.008430  186.960759  29.825173   \n",
      "57   AAPL  2024-02-20  180.090897 -0.004114  186.361502  34.245553   \n",
      "58   AAPL  2024-02-21  180.844757  0.004186  185.736043  44.551039   \n",
      "\n",
      "    daily_compound_mean  sentiment_lag_1  target_return_1d  \n",
      "49             0.084001        -0.055557         -0.005755  \n",
      "50            -0.088853         0.084001          0.004094  \n",
      "51             0.063408        -0.088853         -0.009002  \n",
      "52            -0.008417         0.063408         -0.011274  \n",
      "53             0.006316        -0.008417         -0.004810  \n",
      "54             0.041078         0.006316         -0.001575  \n",
      "55            -0.079968         0.041078         -0.008430  \n",
      "56            -0.170148        -0.079968         -0.004114  \n",
      "57             0.153274        -0.170148          0.004186  \n",
      "58            -0.131494         0.153274          0.011244  \n"
     ]
    }
   ],
   "source": [
    "def engineer_sentiment_features(df):\n",
    "    \"\"\"Create sentiment-based features\"\"\"\n",
    "    print(\"\\nðŸ˜Š Engineering sentiment features...\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['ticker', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for ticker in df['ticker'].unique():\n",
    "        ticker_data = df[df['ticker'] == ticker].copy()\n",
    "        \n",
    "        # Use daily_compound_mean as main sentiment column\n",
    "        if 'daily_compound_mean' in ticker_data.columns:\n",
    "            main_sentiment_col = 'daily_compound_mean'\n",
    "            \n",
    "            # Lagged sentiment features\n",
    "            for lag in [1, 2, 3, 5]:\n",
    "                ticker_data[f'sentiment_lag_{lag}'] = ticker_data[main_sentiment_col].shift(lag)\n",
    "            \n",
    "            # Rolling sentiment statistics\n",
    "            for window in [3, 5, 10]:\n",
    "                ticker_data[f'sentiment_rolling_mean_{window}'] = ticker_data[main_sentiment_col].rolling(window).mean()\n",
    "                ticker_data[f'sentiment_rolling_std_{window}'] = ticker_data[main_sentiment_col].rolling(window).std()\n",
    "            \n",
    "            # Sentiment momentum\n",
    "            ticker_data['sentiment_momentum_5'] = ticker_data[main_sentiment_col] - ticker_data[main_sentiment_col].shift(5)\n",
    "            \n",
    "            # Sentiment volatility\n",
    "            ticker_data['sentiment_volatility_5d'] = ticker_data[main_sentiment_col].rolling(5).std()\n",
    "            \n",
    "            # Sentiment extremes\n",
    "            ticker_data['sentiment_extreme_positive'] = (ticker_data[main_sentiment_col] > ticker_data[main_sentiment_col].rolling(20).quantile(0.8)).astype(int)\n",
    "            ticker_data['sentiment_extreme_negative'] = (ticker_data[main_sentiment_col] < ticker_data[main_sentiment_col].rolling(20).quantile(0.2)).astype(int)\n",
    "            \n",
    "            # Sentiment-price interaction\n",
    "            if 'return' in ticker_data.columns:\n",
    "                ticker_data['sentiment_return_interaction'] = ticker_data[main_sentiment_col] * ticker_data['return']\n",
    "            \n",
    "            if 'volume' in ticker_data.columns:\n",
    "                ticker_data['sentiment_volume_interaction'] = ticker_data[main_sentiment_col] * ticker_data['volume']\n",
    "        \n",
    "        results.append(ticker_data)\n",
    "    \n",
    "    df_final = pd.concat(results, ignore_index=True)\n",
    "    print(\"âœ… Sentiment features engineered\")\n",
    "    return df_final\n",
    "\n",
    "def create_target_variables(df):\n",
    "    \"\"\"Create target variables for machine learning\"\"\"\n",
    "    print(\"ðŸŽ¯ Creating target variables...\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['ticker', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for ticker in df['ticker'].unique():\n",
    "        ticker_data = df[df['ticker'] == ticker].copy()\n",
    "        \n",
    "        if 'return' in ticker_data.columns:\n",
    "            # Future returns for different horizons\n",
    "            horizons = [1, 3, 5]  # 1-day, 3-day, 5-day ahead\n",
    "            \n",
    "            for horizon in horizons:\n",
    "                # Future return\n",
    "                ticker_data[f'target_return_{horizon}d'] = ticker_data['return'].shift(-horizon)\n",
    "                \n",
    "                # Binary classification: will price go up (1) or down (0)\n",
    "                ticker_data[f'target_direction_{horizon}d'] = (ticker_data[f'target_return_{horizon}d'] > 0).astype(int)\n",
    "        \n",
    "        results.append(ticker_data)\n",
    "    \n",
    "    df_final = pd.concat(results, ignore_index=True)\n",
    "    print(\"âœ… Target variables created\")\n",
    "    return df_final\n",
    "\n",
    "def finalize_features(df):\n",
    "    \"\"\"Final processing and cleaning of features\"\"\"\n",
    "    print(\"ðŸ§¹ Finalizing features...\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Remove rows with too many NaN values (from rolling calculations)\n",
    "    initial_rows = len(df)\n",
    "    df = df.dropna()\n",
    "    final_rows = len(df)\n",
    "    \n",
    "    print(f\"   Rows before cleaning: {initial_rows:,}\")\n",
    "    print(f\"   Rows after cleaning: {final_rows:,}\")\n",
    "    print(f\"   Total columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Feature categories\n",
    "    feature_categories = {\n",
    "        'Price Features': [col for col in df.columns if any(x in col for x in ['close', 'high', 'low', 'sma', 'ema', 'bb', 'return', 'volatility'])],\n",
    "        'Volume Features': [col for col in df.columns if 'volume' in col],\n",
    "        'Technical Indicators': [col for col in df.columns if any(x in col for x in ['rsi', 'macd', 'bb'])],\n",
    "        'Sentiment Features': [col for col in df.columns if any(x in col for x in ['sentiment', 'compound'])],\n",
    "        'Target Variables': [col for col in df.columns if 'target' in col]\n",
    "    }\n",
    "    \n",
    "    print(\"\\nðŸ“Š FEATURE SUMMARY:\")\n",
    "    for category, features in feature_categories.items():\n",
    "        print(f\"   {category}: {len(features)} features\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the complete feature engineering pipeline\n",
    "print(\"\\nðŸ”§ Running complete feature engineering pipeline...\")\n",
    "\n",
    "# Apply sentiment features\n",
    "merged_data = engineer_sentiment_features(merged_data)\n",
    "\n",
    "# Create target variables\n",
    "merged_data = create_target_variables(merged_data)\n",
    "\n",
    "# Final processing\n",
    "features_df = finalize_features(merged_data)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ FEATURE ENGINEERING COMPLETED!\")\n",
    "print(f\"Final dataset shape: {features_df.shape}\")\n",
    "print(f\"Total features: {len(features_df.columns)}\")\n",
    "\n",
    "# Save the engineered features\n",
    "output_path = os.path.join(PROCESSED_DIR, \"engineered_features.csv\")\n",
    "features_df.to_csv(output_path, index=False)\n",
    "print(f\"ðŸ’¾ Engineered features saved to: {output_path}\")\n",
    "\n",
    "# Display sample of the final data\n",
    "print(f\"\\nðŸ“‹ Sample of engineered features:\")\n",
    "sample_cols = ['ticker', 'date', 'close', 'return', 'sma_20', 'rsi_14', 'daily_compound_mean', 'sentiment_lag_1', 'target_return_1d']\n",
    "available_cols = [col for col in sample_cols if col in features_df.columns]\n",
    "print(features_df[available_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036d0119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ddf04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c25828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac732cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab338e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
